{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing with NSMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For sentiment analysis, we use the Naver Movie Corpus (https://github.com/e9t/nsmc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_documents(filename):\n",
    "    # NSMC import function\n",
    "    with open(filename, encoding=\"utf-8\") as f:\n",
    "        documents = [line.split('\\t')for line in f.read().splitlines()]\n",
    "        documents = documents[1:]\n",
    "    return documents\n",
    "    \n",
    "train_docs = read_documents(\"/Users/shim/dl-python-SentimentAnalysis/data/ratings_train.txt\")\n",
    "test_docs = read_documents(\"/Users/shim/dl-python-SentimentAnalysis/data/ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_docs))\n",
    "print(len(test_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "from konlpy.tag import Okt\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(doc):\n",
    "    # A function to remove letters except Korean.\n",
    "    doc = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", doc)\n",
    "    return doc\n",
    "\n",
    "def define_stopwords(path):\n",
    "    \n",
    "    SW = set()\n",
    "    # How to add a boolean 1.\n",
    "    # SW.add(\"there is\")\n",
    "    \n",
    "    # How to add a stopword 2.\n",
    "    # Add directly to stopwords-en.txt\n",
    "    with open(path) as f:\n",
    "        for word in f:\n",
    "            SW.add(word)\n",
    "            \n",
    "    return SW\n",
    "\n",
    "def text_tokenizing(doc):\n",
    "    return [word for word in mecab.morphs(doc) if word not in SW and len(word) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizes the imported data with part-of-speech tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stemmer\n",
    "okt = Okt()\n",
    "mecab = Mecab()\n",
    "\n",
    "SW = define_stopwords(\"/Users/shim/dl-python-SentimentAnalysis/Konlpy/stopwords-ko.txt\")\n",
    "\n",
    "# Since there are 200,000 texts, it takes time to clean them.\n",
    "# Let's organize the code so that once it's created, \n",
    "# it can be loaded when the code is run again without having to refine it again.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the histogram using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check basic information to analyze the data.\n",
    "\n",
    "* Perform preprocessing using the NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "total_tokens = [token for doc in train_data for token in doc[0]]\n",
    "print(len(total_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(total_tokens, name='NMSC')\n",
    "print(len(set(text.tokens)))\n",
    "pprint(text.vocab().most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram 그리기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "from matplotlib import font_manager, rc\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "if platform.system() == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':\n",
    "    font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "else:\n",
    "    print('Unknown system... sorry~~~~')\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "text.plot(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordCloud 그리기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud 라이브러리를 설치합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "data = text.vocab().most_common(50)\n",
    "\n",
    "# for windows : font_path='c:/Windows/Fonts/malgun.ttf'\n",
    "wordcloud = WordCloud(font_path='/Library/Fonts/AppleGothic.ttf',\n",
    "                      relative_scaling = 0.2,\n",
    "                      #stopwords=STOPWORDS,\n",
    "                      background_color='white',\n",
    "                      ).generate_from_frequencies(dict(data))\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
